{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>import numpy as np<br />\n",
    "import pandas as pd</p>\n",
    "<p>df=pd.read_excel(\"Input.xlsx\")</p>\n",
    "<p>import requests<br />\n",
    "from bs4 import BeautifulSoup<br />\n",
    "import os</p>\n",
    "<p>def extract_article(url):</p>\n",
    "<p>response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.content, 'html.parser')</p>\n",
    "<p>title = soup.find('title').get_text()</p>\n",
    "<p>article_content = soup.find('article')</p>\n",
    "<p>article_text = ''<br />\n",
    "if article_content:<br />\n",
    "for paragraph in article_content.find_all('p'): article_text +=\n",
    "paragraph.get_text() + '\\n'</p>\n",
    "<p>return title, article_text<br />\n",
    "else:<br />\n",
    "returnNone, None</p>\n",
    "<p>def save_article_to_file(url_id, title, article_text):</p>\n",
    "<p>ifnot os.path.exists('article_texts'):\n",
    "os.makedirs('article_texts')</p>\n",
    "<p>filename = f'article_texts/{url_id}.txt'</p>\n",
    "<p>withopen(filename, 'w', encoding='utf-8') asfile: file.write(title +\n",
    "'\\n\\n')<br />\n",
    "file.write(article_text)</p>\n",
    "<p>url =\n",
    "'https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>url_id =\n",
    "'insights.blackcoffer_rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future'</p>\n",
    "<p>title, article_text = extract_article(url)<br />\n",
    "if title and article_text:<br />\n",
    "save_article_to_file(url_id, title, article_text)<br />\n",
    "print(f'Article \"{title}\" saved successfully.')<br />\n",
    "else:<br />\n",
    "print('Failed to fetch the webpage or extract article content.')</p>\n",
    "<p>Article \"Rising IT Cities and Their Impact on the Economy,<br />\n",
    "Environment, Infrastructure, and City Life in Future -\n",
    "BlackcofferInsights\" saved successfully.</p>\n",
    "<p>!pip install afinn</p>\n",
    "<p>Collecting afinn</p>\n",
    "</blockquote>\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>Downloading afinn-0.1.tar.gz (52 kB)</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr class=\"odd\">\n",
    "<td><blockquote>\n",
    "<p>kB/s eta 0:00:00</p>\n",
    "</blockquote>\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th>5</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<blockquote>\n",
    "<p>0:00:01 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.6/52.6 kB\n",
    "957.6</p>\n",
    "<p>etadata (setup.py) ... e=afinn-0.1-py3-none-any.whl\n",
    "size=53429sha256=8ea0b7ca6c2b2c6e588485a78fb8e0495079583c86e6e937a2e131c119d636a━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "0.0/52.6 kB ? eta -:--:-- ━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━\n",
    "30.7/52.6 kB 1.6 MB/s eta</p>\n",
    "<p>Stored in directory:<br />\n",
    "/root/.cache/pip/wheels/b0/05/90/43f79196199a138fb486902fceca30a2d1b52\n",
    "28e6d2db8eb90<br />\n",
    "Successfully built afinn<br />\n",
    "Installing collected packages: afinn<br />\n",
    "Successfully installed afinn-0.1</p>\n",
    "<p>import requests<br />\n",
    "from bs4 import BeautifulSoup<br />\n",
    "from afinn import Afinn</p>\n",
    "<p>def extract_text_from_url(url):</p>\n",
    "<p>response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.text, 'html.parser')</p>\n",
    "<p>text_content = ' '.join([p.get_text() for p in\n",
    "soup.find_all('p')])</p>\n",
    "<p>return text_content</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>else:<br />\n",
    "print(\"Failed to fetch the webpage.\") returnNone</p>\n",
    "<p>def calculate_positive_score(text):<br />\n",
    "afinn = Afinn()<br />\n",
    "return afinn.score(text)</p>\n",
    "<p>url =\n",
    "'https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'<br />\n",
    "text_content = extract_text_from_url(url)</p>\n",
    "<p>if text_content:<br />\n",
    "positive_score = calculate_positive_score(text_content) print(\"Positive\n",
    "Score:\", positive_score)<br />\n",
    "else:<br />\n",
    "print(\"No text content extracted from the webpage.\")</p>\n",
    "<p>Positive Score: 97.0</p>\n",
    "<p>import requests<br />\n",
    "from bs4 import BeautifulSoup<br />\n",
    "from afinn import Afinn</p>\n",
    "<p>def extract_text_from_url(url):<br />\n",
    "response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.text, 'html.parser')</p>\n",
    "<p>text_content = ' '.join([p.get_text() for p in\n",
    "soup.find_all('p')])</p>\n",
    "<p>return text_content<br />\n",
    "else:<br />\n",
    "print(\"Failed to fetch the webpage.\") returnNone</p>\n",
    "<p>def calculate_negative_score(text):<br />\n",
    "afinn = Afinn()<br />\n",
    "return afinn.score(text)</p>\n",
    "<p>url =\n",
    "'https://insights.blackcoffer.com/rising-it-cities-and-their-</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'<br />\n",
    "text_content = extract_text_from_url(url)</p>\n",
    "<p>if text_content:<br />\n",
    "negative_score = calculate_negative_score(text_content) print(\"Negative\n",
    "Score:\", negative_score)<br />\n",
    "else:<br />\n",
    "print(\"No text content extracted from the webpage.\")</p>\n",
    "<p>Negative Score: 97.0</p>\n",
    "<p>def extract_text_from_url(url):</p>\n",
    "<p>response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.text, 'html.parser')</p>\n",
    "<p>text_content = ' '.join([p.get_text() for p in\n",
    "soup.find_all('p')])</p>\n",
    "<p>return text_content<br />\n",
    "else:<br />\n",
    "print(\"Failed to fetch the webpage.\") returnNone</p>\n",
    "<p>def calculate_polarity_score(text):<br />\n",
    "afinn = Afinn()</p>\n",
    "<p>positive_score = afinn.score(text)<br />\n",
    "negative_score = afinn.score(text)</p>\n",
    "<p>polarity_score = (positive_score - negative_score) / max(1,\n",
    "positive_score + negative_score)<br />\n",
    "return polarity_score</p>\n",
    "<p>url='https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'<br />\n",
    "text_content = extract_text_from_url(url)</p>\n",
    "<p>if text_content:</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>polarity_score = calculate_polarity_score(text_content)\n",
    "print(\"Polarity Score:\", polarity_score)<br />\n",
    "else:<br />\n",
    "print(\"No text content extracted from the webpage.\")</p>\n",
    "<p>Polarity Score: 0.0</p>\n",
    "<p>import requests<br />\n",
    "from bs4 import BeautifulSoup<br />\n",
    "import re</p>\n",
    "<p>def extract_text_from_url(url):</p>\n",
    "<p>response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.text, 'html.parser')</p>\n",
    "<p>text_content = ' '.join([p.get_text() for p in\n",
    "soup.find_all('p')])</p>\n",
    "<p>return text_content<br />\n",
    "else:<br />\n",
    "print(\"Failed to fetch the webpage.\") returnNone</p>\n",
    "<p>def clean_text(text):</p>\n",
    "<p>cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text) cleaned_text =\n",
    "re.sub(r'\\s+', ' ', cleaned_text) return cleaned_text.strip()</p>\n",
    "<p>def count_total_words(text):<br />\n",
    "words = text.split()<br />\n",
    "returnlen(words)</p>\n",
    "<p>url =\n",
    "'https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'<br />\n",
    "text_content = extract_text_from_url(url)</p>\n",
    "<p>if text_content:<br />\n",
    "cleaned_text = clean_text(text_content)<br />\n",
    "total_words = count_total_words(cleaned_text)</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>print(\"Total Words After Cleaning:\", total_words) else:<br />\n",
    "print(\"No text content extracted from the webpage.\")</p>\n",
    "<p>Total Words After Cleaning: 1583</p>\n",
    "<p>!pip install afinn</p>\n",
    "<p>Collecting afinn</p>\n",
    "</blockquote>\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>Downloading afinn-0.1.tar.gz (52 kB)</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "<blockquote>\n",
    "<p>0:00:00</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr class=\"odd\">\n",
    "<td><table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th>9</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<blockquote>\n",
    "<p>etadata (setup.py) ... e=afinn-0.1-py3-none-any.whl\n",
    "size=53429sha256=11dde09d3ac7ae57a494d9f93eeca41a32b8eb8adf807e82a466dc9aad73aa7━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "0.0/52.6 kB ? eta -:--:-- ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "52.6/52.6 kB 1.7 MB/s eta</p>\n",
    "<p>Stored in directory:<br />\n",
    "/root/.cache/pip/wheels/b0/05/90/43f79196199a138fb486902fceca30a2d1b52\n",
    "28e6d2db8eb90<br />\n",
    "Successfully built afinn<br />\n",
    "Installing collected packages: afinn<br />\n",
    "Successfully installed afinn-0.1</p>\n",
    "<p>import requests<br />\n",
    "from bs4 import BeautifulSoup<br />\n",
    "import re<br />\n",
    "from afinn import Afinn</p>\n",
    "<p>def extract_text_from_url(url):</p>\n",
    "<p>response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.text, 'html.parser')</p>\n",
    "<p>text_content = ' '.join([p.get_text() for p in\n",
    "soup.find_all('p')])</p>\n",
    "<p>return text_content<br />\n",
    "else:<br />\n",
    "print(\"Failed to fetch the webpage.\") returnNone</p>\n",
    "<p>def calculate_subjectivity_score(text): afinn = Afinn()<br />\n",
    "positive_score = afinn.score(text)</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>negative_score = afinn.score(text)<br />\n",
    "total_words=len(text.split())<br />\n",
    "subjectivity_score= (positive_score + negative_score) /\n",
    "((total_words)+0.000001)<br />\n",
    "return subjectivity_score</p>\n",
    "<p>url='https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'<br />\n",
    "text_content = extract_text_from_url(url)</p>\n",
    "<p>if text_content:<br />\n",
    "subjectivity_score = calculate_subjectivity_score(text_content)\n",
    "print(\"Subjectivity Score:\", subjectivity_score)<br />\n",
    "else:<br />\n",
    "print(\"No text content extracted from the webpage.\")</p>\n",
    "<p>Subjectivity Score: 0.12132582856702574</p>\n",
    "<p>import requests<br />\n",
    "from bs4 import BeautifulSoup<br />\n",
    "import re</p>\n",
    "<p>def extract_text_from_url(url):</p>\n",
    "<p>response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.text, 'html.parser')</p>\n",
    "<p>text_content = ' '.join([p.get_text() for p in\n",
    "soup.find_all('p')])</p>\n",
    "<p>return text_content<br />\n",
    "else:<br />\n",
    "print(\"Failed to fetch the webpage.\") returnNone</p>\n",
    "<p>def calculate_average_sentence_length(text):</p>\n",
    "<p>sentences = re.split(r'[.!?]', text)</p>\n",
    "<p>num_sentences = len(sentences)</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>total_words = sum(len(sentence.split()) for sentence in\n",
    "sentences)</p>\n",
    "<p>if num_sentences &gt; 0:<br />\n",
    "average_sentence_length = total_words / num_sentences return\n",
    "average_sentence_length<br />\n",
    "else:<br />\n",
    "return0</p>\n",
    "<p>url =\n",
    "'https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'<br />\n",
    "text_content = extract_text_from_url(url)</p>\n",
    "<p>if text_content:<br />\n",
    "average_sentence_length =<br />\n",
    "calculate_average_sentence_length(text_content)<br />\n",
    "print(\"Average Sentence Length:\", average_sentence_length) else:<br />\n",
    "print(\"No text content extracted from the webpage.\")</p>\n",
    "<p>Average Sentence Length: 18.847058823529412</p>\n",
    "<p>!pip install nltk</p>\n",
    "<p>Requirement already satisfied: nltk in\n",
    "/usr/local/lib/python3.10/dist-packages (3.8.1)<br />\n",
    "Requirement already satisfied: click in<br />\n",
    "/usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)<br />\n",
    "Requirement already satisfied: joblib in<br />\n",
    "/usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)<br />\n",
    "Requirement already satisfied: regex&gt;=2021.8.3 in<br />\n",
    "/usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
    "Requirement already satisfied: tqdm in\n",
    "/usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)</p>\n",
    "<p>import nltk<br />\n",
    "nltk.download('punkt')<br />\n",
    "nltk.download('cmudict')</p>\n",
    "<p>[nltk_data] Downloading package punkt to /root/nltk_data...\n",
    "[nltk_data] Package punkt is already up-to-date!</p>\n",
    "<p>[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
    "[nltk_data] Unzipping corpora/cmudict.zip.</p>\n",
    "<p>True</p>\n",
    "<p>import requests<br />\n",
    "from bs4 import BeautifulSoup</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>import re<br />\n",
    "from nltk.tokenize import word_tokenize from nltk.corpus import\n",
    "cmudict</p>\n",
    "<p>def extract_text_from_url(url):</p>\n",
    "<p>response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.text, 'html.parser')</p>\n",
    "<p>text_content = ' '.join([p.get_text() for p in\n",
    "soup.find_all('p')])</p>\n",
    "<p>return text_content<br />\n",
    "else:<br />\n",
    "print(\"Failed to fetch the webpage.\") returnNone</p>\n",
    "<p>def calculate_percentage_complex_words(text):</p>\n",
    "<p>words = word_tokenize(text)</p>\n",
    "<p>cmu_dict = cmudict.dict()</p>\n",
    "<p>num_complex_words = sum(1for word in words if\n",
    "len(cmu_dict.get(word.lower(), [])) &gt; 2)</p>\n",
    "<p>total_words = len(words)</p>\n",
    "</blockquote>\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 50%\" />\n",
    "<col style=\"width: 50%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th>100</th>\n",
    "<th><blockquote>\n",
    "<p>if total_words &gt; 0:<br />\n",
    "percentage_complex_words = (num_complex_words / total_words) *</p>\n",
    "<p>return percentage_complex_words else:<br />\n",
    "return0</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "<blockquote>\n",
    "<p>url =\n",
    "'https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'<br />\n",
    "text_content = extract_text_from_url(url)</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>if text_content:<br />\n",
    "percentage_complex_words =<br />\n",
    "calculate_percentage_complex_words(text_content)<br />\n",
    "print(\"Percentage of Complex Words:\", percentage_complex_words)\n",
    "else:<br />\n",
    "print(\"No text content extracted from the webpage.\")</p>\n",
    "<p>Percentage of Complex Words: 9.838709677419356</p>\n",
    "<p>import requests<br />\n",
    "from bs4 import BeautifulSoup<br />\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize from nltk.corpus\n",
    "import cmudict</p>\n",
    "<p>def extract_text_from_url(url):</p>\n",
    "<p>response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.text, 'html.parser')</p>\n",
    "<p>text_content = ' '.join([p.get_text() for p in\n",
    "soup.find_all('p')])</p>\n",
    "<p>return text_content<br />\n",
    "else:<br />\n",
    "print(\"Failed to fetch the webpage.\") returnNone</p>\n",
    "<p>def calculate_fog_index(text):</p>\n",
    "<p>sentences = sent_tokenize(text)</p>\n",
    "<p>words = word_tokenize(text)</p>\n",
    "<p>avg_words_per_sentence = len(words) / len(sentences)</p>\n",
    "<p>cmu_dict = cmudict.dict()</p>\n",
    "<p>num_complex_words = sum(1for word in words if\n",
    "len(cmu_dict.get(word.lower(), [])) &gt;= 3)</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>percentage_complex_words = (num_complex_words / len(words)) * 100</p>\n",
    "<p>fog_index = 0.4 * (avg_words_per_sentence +\n",
    "percentage_complex_words)</p>\n",
    "<p>return fog_index</p>\n",
    "<p>url =\n",
    "'https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'<br />\n",
    "text_content = extract_text_from_url(url)</p>\n",
    "<p>if text_content:<br />\n",
    "fog_index = calculate_fog_index(text_content)<br />\n",
    "print(\"Fog Index:\", fog_index)<br />\n",
    "else:<br />\n",
    "print(\"No text content extracted from the webpage.\")</p>\n",
    "<p>Fog Index: 13.00865460267506</p>\n",
    "<p>import requests<br />\n",
    "from bs4 import BeautifulSoup<br />\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize</p>\n",
    "<p>def extract_text_from_url(url):</p>\n",
    "<p>response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.text, 'html.parser')</p>\n",
    "<p>text_content = ' '.join([p.get_text() for p in\n",
    "soup.find_all('p')])</p>\n",
    "<p>return text_content<br />\n",
    "else:<br />\n",
    "print(\"Failed to fetch the webpage.\") returnNone</p>\n",
    "<p>def calculate_avg_words_per_sentence(text):</p>\n",
    "<p>sentences = sent_tokenize(text)</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>total_words = sum(len(word_tokenize(sentence)) for sentence in\n",
    "sentences)</p>\n",
    "<p>avg_words_per_sentence = total_words / len(sentences) if\n",
    "len(sentences) &gt; 0else0</p>\n",
    "<p>return avg_words_per_sentence</p>\n",
    "<p>url =\n",
    "'https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'<br />\n",
    "text_content = extract_text_from_url(url)</p>\n",
    "<p>if text_content:<br />\n",
    "avg_words_per_sentence =<br />\n",
    "calculate_avg_words_per_sentence(text_content)<br />\n",
    "print(\"Average Number of Words Per Sentence:\",\n",
    "avg_words_per_sentence)<br />\n",
    "else:<br />\n",
    "print(\"No text content extracted from the webpage.\")</p>\n",
    "<p>Average Number of Words Per Sentence: 22.682926829268293</p>\n",
    "<p>import requests<br />\n",
    "from bs4 import BeautifulSoup<br />\n",
    "from nltk.tokenize import word_tokenize from nltk.corpus import\n",
    "cmudict</p>\n",
    "<p>def extract_text_from_url(url):</p>\n",
    "<p>response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.text, 'html.parser')</p>\n",
    "<p>text_content = ' '.join([p.get_text() for p in\n",
    "soup.find_all('p')])</p>\n",
    "<p>return text_content<br />\n",
    "else:<br />\n",
    "print(\"Failed to fetch the webpage.\") returnNone</p>\n",
    "<p>def calculate_complex_word_count(text):</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>words = word_tokenize(text)</p>\n",
    "<p>cmu_dict = cmudict.dict()</p>\n",
    "<p>complex_word_count = sum(1for word in words if\n",
    "len(cmu_dict.get(word.lower(), [])) &gt;= 3)</p>\n",
    "<p>return complex_word_count</p>\n",
    "<p>url =\n",
    "'https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'<br />\n",
    "text_content = extract_text_from_url(url)</p>\n",
    "<p>if text_content:<br />\n",
    "complex_word_count = calculate_complex_word_count(text_content)\n",
    "print(\"Complex Word Count:\", complex_word_count)<br />\n",
    "else:<br />\n",
    "print(\"No text content extracted from the webpage.\")</p>\n",
    "<p>Complex Word Count: 183</p>\n",
    "<p>import requests<br />\n",
    "from bs4 import BeautifulSoup<br />\n",
    "from nltk.tokenize import word_tokenize</p>\n",
    "<p>def extract_text_from_url(url):</p>\n",
    "<p>response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.text, 'html.parser')</p>\n",
    "<p>text_content = ' '.join([p.get_text() for p in\n",
    "soup.find_all('p')])</p>\n",
    "<p>return text_content<br />\n",
    "else:<br />\n",
    "print(\"Failed to fetch the webpage.\") returnNone</p>\n",
    "<p>def calculate_word_count(text):</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>words = word_tokenize(text)</p>\n",
    "<p>word_count = len(words)</p>\n",
    "<p>return word_count</p>\n",
    "<p>url =\n",
    "'https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'<br />\n",
    "text_content = extract_text_from_url(url)</p>\n",
    "<p>if text_content:<br />\n",
    "word_count = calculate_word_count(text_content) print(\"Word Count:\",\n",
    "word_count)<br />\n",
    "else:<br />\n",
    "print(\"No text content extracted from the webpage.\")</p>\n",
    "<p>Word Count: 1860</p>\n",
    "<p>import requests<br />\n",
    "from bs4 import BeautifulSoup<br />\n",
    "from nltk.tokenize import word_tokenize from nltk.corpus import\n",
    "cmudict</p>\n",
    "<p>def extract_text_from_url(url):</p>\n",
    "<p>response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.text, 'html.parser')</p>\n",
    "<p>text_content = ' '.join([p.get_text() for p in\n",
    "soup.find_all('p')])</p>\n",
    "<p>return text_content<br />\n",
    "else:<br />\n",
    "print(\"Failed to fetch the webpage.\") returnNone</p>\n",
    "<p>def count_syllables(word, cmu_dict):<br />\n",
    "if word.lower() in cmu_dict:<br />\n",
    "return [len(list(y for y in x if y[-1].isdigit())) for x in\n",
    "cmu_dict[word.lower()]][0]</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>else:<br />\n",
    "return0</p>\n",
    "<p>def calculate_syllables_per_word(text):</p>\n",
    "<p>words = word_tokenize(text)</p>\n",
    "<p>cmu_dict = cmudict.dict()</p>\n",
    "<p>total_syllables = sum(count_syllables(word, cmu_dict) for word in\n",
    "words)</p>\n",
    "<p>syllables_per_word = total_syllables / len(words) iflen(words) &gt;\n",
    "0else0</p>\n",
    "<p>return syllables_per_word</p>\n",
    "<p>url =\n",
    "'https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'<br />\n",
    "text_content = extract_text_from_url(url)</p>\n",
    "<p>if text_content:<br />\n",
    "syllables_per_word = calculate_syllables_per_word(text_content)\n",
    "print(\"Syllables Per Word:\", syllables_per_word)<br />\n",
    "else:<br />\n",
    "print(\"No text content extracted from the webpage.\")</p>\n",
    "<p>Syllables Per Word: 1.549462365591398</p>\n",
    "<p>import requests<br />\n",
    "from bs4 import BeautifulSoup<br />\n",
    "from nltk.tokenize import word_tokenize</p>\n",
    "<p>def extract_text_from_url(url):</p>\n",
    "<p>response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.text, 'html.parser')</p>\n",
    "<p>text_content = ' '.join([p.get_text() for p in\n",
    "soup.find_all('p')])</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>return text_content<br />\n",
    "else:<br />\n",
    "print(\"Failed to fetch the webpage.\") returnNone</p>\n",
    "<p>def find_personal_pronouns(text):</p>\n",
    "<p>words = word_tokenize(text)</p>\n",
    "<p>personal_pronouns = [\"i\", \"me\", \"my\", \"mine\", \"myself\", \"you\",\n",
    "\"your\", \"yours\", \"yourself\", \"he\", \"him\", \"his\", \"himself\", \"she\",\n",
    "\"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"we\", \"us\", \"our\",\n",
    "\"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourselves\", \"they\",\n",
    "\"them\", \"their\", \"theirs\", \"themselves\"]</p>\n",
    "<p>personal_pronoun_count = sum(1for word in words if word.lower() in\n",
    "personal_pronouns)</p>\n",
    "<p>return personal_pronoun_count</p>\n",
    "<p>url =\n",
    "'https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'<br />\n",
    "text_content = extract_text_from_url(url)</p>\n",
    "<p>if text_content:<br />\n",
    "personal_pronoun_count = find_personal_pronouns(text_content)\n",
    "print(\"Personal Pronoun Count:\", personal_pronoun_count) else:<br />\n",
    "print(\"No text content extracted from the webpage.\")</p>\n",
    "<p>Personal Pronoun Count: 38</p>\n",
    "<p>import requests<br />\n",
    "from bs4 import BeautifulSoup<br />\n",
    "from nltk.tokenize import word_tokenize</p>\n",
    "<p>def extract_text_from_url(url):</p>\n",
    "<p>response = requests.get(url)</p>\n",
    "<p>if response.status_code == 200:</p>\n",
    "<p>soup = BeautifulSoup(response.text, 'html.parser')</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>text_content = ' '.join([p.get_text() for p in\n",
    "soup.find_all('p')])</p>\n",
    "<p>return text_content<br />\n",
    "else:<br />\n",
    "print(\"Failed to fetch the webpage.\") returnNone</p>\n",
    "<p>def calculate_avg_word_length(text):</p>\n",
    "<p>words = word_tokenize(text)</p>\n",
    "<p>total_length = sum(len(word) for word in words)</p>\n",
    "</blockquote>\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 50%\" />\n",
    "<col style=\"width: 50%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th>0</th>\n",
    "<th>avg_word_length = total_length / len(words) iflen(words) &gt;\n",
    "0else</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "<blockquote>\n",
    "<p>return avg_word_length</p>\n",
    "<p>url =\n",
    "'https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/'<br />\n",
    "text_content = extract_text_from_url(url)</p>\n",
    "<p>if text_content:<br />\n",
    "avg_word_length = calculate_avg_word_length(text_content) print(\"Average\n",
    "Word Length:\", avg_word_length)<br />\n",
    "else:<br />\n",
    "print(\"No text content extracted from the webpage.\")</p>\n",
    "<p>Average Word Length: 4.897849462365591</p>\n",
    "<p>import pandas as pd</p>\n",
    "<p>data = {<br />\n",
    "\"URL_ID\":\n",
    "[\"https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/\"],<br />\n",
    "\"POSITIVE SCORE\": [97.0],<br />\n",
    "\"NEGATIVE SCORE\": [97.0],<br />\n",
    "\"POLARITY SCORE\": [0.0],<br />\n",
    "\"SUBJECTIVITY SCORE\": [0.12132582856702574],<br />\n",
    "\"AVG SENTENCE LENGTH\": [18.847058823529412],<br />\n",
    "\"PERCENTAGE OF COMPLEX WORDS\": [9.838709677419356],<br />\n",
    "\"FOG INDEX\": [13.00865460267506],</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><table>\n",
    "<colgroup>\n",
    "<col style=\"width: 50%\" />\n",
    "<col style=\"width: 50%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>}</p>\n",
    "</blockquote></th>\n",
    "<th><blockquote>\n",
    "<p>\"AVG NUMBER OF WORDS PER SENTENCE\": [22.682926829268293], \"COMPLEX\n",
    "WORD COUNT\": [183],<br />\n",
    "\"WORD COUNT\": [1860],<br />\n",
    "\"SYLLABLE PER WORD\": [1.549462365591398],<br />\n",
    "\"PERSONAL PRONOUNS\": [38],<br />\n",
    "\"AVG WORD LENGTH\": [4.897849462365591]</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "<blockquote>\n",
    "<p>df = pd.DataFrame(data)</p>\n",
    "<p>output_datafile = \"Output Data Structure.xlsx\"\n",
    "df.to_excel(output_datafile, index=False)<br />\n",
    "print(\"Output file saved as:\", output_datafile)</p>\n",
    "<p>Output file saved as: Output Data Structure.xlsx</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
